Solutions for Homework 2
================
Jiajun Tao
2022-09-27

### Problem 1

First we import and clean data from
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. We import the data,
specify the variables’ type, clean variable names, select the interested
columns, and update `entry` to a logical variable.

``` r
nyc_transit_df = read_csv('data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv', col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE)
  )
dim(nyc_transit_df)
## [1] 1868   19
```

Now the resulting dataset has 1868 rows and 19 columns.

These data are not tidy by now. For examples, there are too many
variables regarding routes served. We should convert `route` variables
from wide to long format.

There are 465 distinct stations.

84 stations are ADA compliant.

The proportion of station entrances / exits without vending allow
entrance is 0.38

Last, we write a code chunk to identify stations that serve the A train.
We convert `route` to longer format and use `select` and `distinct`
function to answer the questions.

``` r
A_df =
  nyc_transit_df %>% 
  pivot_longer(
    route1:route11,
    names_to = 'route_number',
    values_to = 'route_name'
    ) %>% 
  filter(route_name == 'A')
```

60 distinct stations serve the A train. And of these stations that serve
the A train, 17 are ADA compliant.

### Problem 2

First we import Mr. Trash Wheel dataset, specify the sheet, omit
non-data entries using `range`, clean variable names, select
dumpster-specific data using `drop_na`, and round the number of sports
balls to the nearest integer and converts the result to an integer
variable using `as.integer`. Since we need to combine two datasets
later, we add an additional variable to keep track of which Trash Wheel
it is. Meanwhile, specify the `dumpster` variable type as double.

``` r
mr_trash_wheel_df = 
  read_excel('data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx', 
             range = "Mr. Trash Wheel!A2:N535") %>% 
  janitor::clean_names() %>% 
  drop_na(year) %>% 
  mutate(
    sports_balls = as.integer(sports_balls),
    type = "Mr Trash Wheel",
    dumpster = as.double(dumpster)
  )
```

Then use a similar process to import Professor Trash Wheel dataset.

``` r
pro_trash_wheel_df =
  read_excel('data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx',
             range = "Professor Trash Wheel!A2:N117") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = as.integer(sports_balls),
    type = "Professor Trash Wheel"
  )
```

Now we combine the two datasets.

``` r
combined_df = 
  bind_rows(mr_trash_wheel_df, pro_trash_wheel_df)

filter(combined_df, type == "Mr Trash Wheel") %>% 
  pull(weight_tons) %>% 
  sum()
## [1] 1449.7

filter(combined_df, type == "Professor Trash Wheel") %>% 
  pull(sports_balls) %>% 
  sum()
## [1] 14

pull(combined_df, homes_powered) %>% 
  sum %>% 
  round
## [1] 22788
```

The combined dataset has 524 rows and 15 columns. The variables include
dumpster number, time(month, year, and date), weight, volume, different
kinds of trash and their amount, homes powered by trash-made
electricity, and the type of Trash Wheel.

In all, there are 453 Mr Trash Wheel dumpster and 71 Professor Trash
Wheel dumpster documented. The total weight of trash collected by
Professor Trash Wheel is 135.5 tons. The total number of sports balls
collected by Mr. Trash Wheel in 2020 is 856. The total volume of trash
collected by Professor Trash Wheel is 1036 yards, while by Mr. Trash
Wheel, the total volume is 6982 yards. Totally, the two Trash Wheels
have powered 2.2788^{4} homes in Maryland with electricity.

# Problem 3

We first import data from `pols-month.csv`, break up the variable `mon`
into `year`, `month`, and `day`; replace month number with month name;
create a `president` variable taking values `gop` and `dem`, remove
`prez_dem`, `prez_gop`, and `day` variable.

``` r
pols_df = read_csv('data/fivethirtyeight_datasets/pols-month.csv') %>% 
  separate(mon, sep = '-', into = c("year","month","day")) %>% 
  mutate(
    month = recode(month,
                   '01' = 'January',
                   '02' = 'February',
                   '03' = 'March',
                   '04' = 'April',
                   '05' = 'May',
                   '06' = 'June',
                   '07' = 'July',
                   '08' = 'August',
                   '09' = 'September',
                   '10' = 'October',
                   '11' = 'November',
                   '12' = 'December'),
    president = recode(prez_dem, `1` = "dem", `0` = "gop")
  ) %>% 
  select(-day, -prez_dem, -prez_gop)
```

Second, we import and clean data from `snp.csv` using a similar process.
We arrange according to year and month for consistency across datasets.

``` r
snp_df = 
  read_csv('data/fivethirtyeight_datasets/snp.csv') %>% 
  separate(date, sep = '/', into = c('month', 'day', 'year')) %>% 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    year = ifelse(year >= 50, year + 1900,
                  year + 2000)
  ) %>% 
  arrange(year, month) %>% 
  mutate(
    month = recode(month,
                   '1' = 'January',
                   '2' = 'February',
                   '3' = 'March',
                   '4' = 'April',
                   '5' = 'May',
                   '6' = 'June',
                   '7' = 'July',
                   '8' = 'August',
                   '9' = 'September',
                   '10' = 'October',
                   '11' = 'November',
                   '12' = 'December'),
  ) %>% 
  select(year, month, close)
```

Third, we tidy the unemployment data imported from `unemployment.csv`.
We switch from wide to long format.

``` r
unemployment_df = 
  read_csv('data/fivethirtyeight_datasets/unemployment.csv') %>% 
  pivot_longer(
    Jan:Dec,
    names_to = 'month',
    values_to = 'unemployment_percentage'
  ) %>% 
  mutate(
    month = recode(month,
                   'Jan' = 'January',
                   'Feb' = 'February',
                   'Mar' = 'March',
                   'Apr' = 'April',
                   'Jun' = 'June',
                   'Jul' = 'July',
                   'Aug' = 'August',
                   'Sep' = 'September',
                   'Oct' = 'October',
                   'Nov' = 'November',
                   'Dec' = 'December')
  ) %>% 
  janitor::clean_names()
```

Finally, we join the datasets by merging snp into pols, and merging
unemployment into the result.

``` r
merged_df = 
  merge(unemployment_df,
        merge(snp_df, pols_df))
```

The first dataset `pols_df` related to the number of national
politicians who are democratic or republican at any given time, so it
contained variables including the time, the number of governors,
senators, and representatives who are democratic or republican, and
whether the president was democratic or republican.

The second dataset `snp_df` related to a representative measure of stock
market, so it contained variables including the time and the closing
values of the S&P stock index on the associated date.

The third dataset `unemployment_df` related to unemployment rates, so it
contained variables including the time and the percentage of
unemployment on the associated date.

The resulting dataset has 786 rows and 11 columns. The range of years is
65. The names of variables include the time(year and month), the
percentage of unemployment, the closing values of the S&P stock index,
the number of national politicians, and whether the president was
democratic or republican. Since I used the `merge` function, the
resulting dataset only kept the rows which the three datasets all have
according to year and month.
